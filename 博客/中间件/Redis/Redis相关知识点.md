## Redis基础概念

### 基础概念

​	Redis是一个高性能的key-value数据库。支持数据持久化，可以将内存中的数据保存在磁盘中，重启的时候再次加载使用。读的速度为110000次/s写的速度为81000次/s。操作都是原子操作。redis支持的类型：String、list、set、Zsetsorted set、Hash等。redis是单进程，单线程单，通过队列技术将并发访问变为串行访问。

* 当Redis内存满了后，写命令会返回错误信息，读命令还是可以正常返回。

### 持久化机制和原理

Redis有两个持久化策略：RDB和AOF

#### RDB快照

​	Redis支持将当前数据的快照存成一个数据文件的持久化机制。而一个持续写入的数据库如何生成快照呢。Redis借助了fork命令的copy on write机制。在生成快照时，将当前进程fork出一个子进程，然后在子进程中循环所有的数据，将数据写如一个临时文件，持久化结束后，用这个临时文件代替上一个持久化文件，也就是rename。由于os的写时复制机制（copy on write)父子进程会共享相同的物理页面，当父进程处理写请求时os会为父进程要修改的页面创建副本，而不是写共享的页面。所以子进程的地址空间内的数据是fork时刻整个数据库的一个快照。即持久化后的数据库的修改不会记录到持久化文件中，这个也是它的一个缺点之一，因为有可能从持久化后到服务器断电之前到数据都会丢失，主要是看项目的取舍。而且RDB快照是全量持久化，并不是增量持久化。

​	在redis客户端中执行`save 60 1000`(60秒内，如果有1000个键被修改就执行RDB)命令即可调用RDB快照的备份。

#### AOF日志

​	AOF日志的全称是Append Only File，是一个追加写入的日志。但是AOF日志文件里面存储的是redis的标准命令，有些命令经过转化，例如删除一个不存在的键，redis认为不会对数据库造成造成修改，所以不会记录在AOF日志文件中，有些命令因为操作系统的不同可能会导致执行结果不同，所以都转换为统一的命令。

* AOF rewrite：功能就是重新生成一份AOF文件，新的AOF文件中一条记录的操作只会有一次，而不像一份老文件那样，可能记录了对同一个值的多次操作。其生成过程和RDB类似，也是fork一个进程，直接遍历数据，写入新的AOF临时文件。在写入新文件的过程中，所有的写操作日志还是会写到原来老的 AOF文件中，同时还会记录在内存缓冲区中。当重完操作完成后，会将所有缓冲区中的日志一次性写入到临时文件中。然后调用原子性的rename命令用新的 AOF文件取代老的AOF文件。 

​	在Redis中对AOF调用write写入后，何时再调用fsync将其写到磁盘上，通过appendfsync选项来控制，下面appendfsync的三个设置项，安全强度逐渐变强。 通过设置配置项来实现AOF备份：`appendonly yes`,通过配置`appendfsync`来设置何时写到磁盘上。

* appendfsync no ：当设置appendfsync为no的时候，Redis不会主动调用fsync去将AOF日志内容同步到磁盘，所以这一切就完全依赖于操作系统的调试了。对大多数Linux操作系统，是每30秒进行一次fsync，将缓冲区中的数据写到磁盘上。 
* appendfsync everysec：当设置appendfsync为everysec的时候，Redis会默认每隔一秒进行一次fsync调用，将缓冲区中的数据写到磁盘。但是当这一 次的fsync调用时长超过1秒时。Redis会采取延迟fsync的策略，再等一秒钟。也就是在两秒后再进行fsync，这一次的fsync就不管会执行多长时间都会进行。这时候由于在fsync时文件描述符会被阻塞，所以当前的写操作就会阻塞。 
* appednfsync always：当设置appendfsync为always时，每一次写操作都会调用一次fsync，这时数据是最安全的，当然，由于每次都会执行fsync，所以其性能也会受到影响。 

### Redis的内存回收策略

​	如果redis占用的内存满了，可以通过设置内存回收策略来进行键值淘汰，配置项为：`maxmemory-policy`。主动清除策略主要有八种：

>- volatile-ttl：在筛选时，会针对设置了过期时间的键值对，根据过期时间的先后进行删除，越早过期的越先被删除。
>
>- volatile-random：就像它的名称一样，在设置了过期时间的键值对中，进行随机删除。
>- volatile-lru：会使用 LRU 算法筛选设置了过期时间的键值对删除。（LRU：最近最少使用）
>- volatile-lfu：会使用 LFU 算法筛选设置了过期时间的键值对删除（LFU：最不经常使用）

>- allkeys-random：从所有键值对中随机选择并删除数据。
>
>- allkeys-lru：使用 LRU 算法在所有数据中进行筛选删除。
>- allkeys-lfu：使用 LFU 算法在所有数据中进行筛选删除。

>* noeviction：不会剔除任何数据，拒绝所有写入操作并返回客户端错误信息"(error) OOM command not allowed when used memory"，此时Redis只响应读操作。

LRU是最近最少使用页面置换算法(Least Recently Used),也就是首先淘汰最长时间未被使用的页面!

LFU是最近最不常用页面置换算法(Least Frequently Used),也就是淘汰一定时期内被访问次数最少的页!

### Redis的键删除策略

​	Redis过期key的删除方式有三种：

* 被动删除：当读/写一个已经过期的key时，会触发惰性删除策略，直接删除掉这个过期key。返回nil。
* 主动删除：由于惰性删除策略无法保证冷数据被及时删掉，所以Redis会定期主动淘汰一批已过期的key。
  * 随机测试100个设置了过期时间的key
  * 删除所有发现的已过期的key
  * 若删除的key超过25个则重复步骤1
* 当前已用内存超过maxmemory限定时，触发主动清理策略。

### Redis集群

​	Redis有三种集群模式：主从模式、Sentinel模式（哨兵模式）、Cluster模式（集群模式）。

#### 主从模式

​	主从模式将数据库分为两种，主库和从库。主数据库可以进行读和写，从数据库只能进行读。多个从数据库对应一个主数据库，从数据库挂了重启后会向主数据库请求同步数据。主数据库挂掉后，不影响从数据库的读，但是不能提供写服务了。

​	机制：当slave启动后，主动向master发送SYNC命令。master接收到SYNC命令后在后台保存快照（RDB持久化）和缓存保存快照这段时间的命令，然后将保存的快照文件和缓存的命令发送给slave。slave接收到快照文件和命令后加载快照文件和缓存的执行命令。复制初始化后，master每次接收到的写命令都会同步发送给slave，保证主从数据一致性。

​	缺点就是主数据挂掉后，redis无法提供写服务。

​	搭建方式：通过下载redis安装包，安装后，通过启动不同的配置文件来达到多个redis服务的目的。在配置文件中配置主数据库和从数据库即可。

##### 流程和细节

建立连接阶段（即准备阶段）

1. 设置master的地址和端口，保存master信息
2. 建立socket链接
3. 发送ping命令（定时器任务）
4. 身份验证
5. 发送slave端口信息
   至此，主从链接成功！

数据同步阶段（注意从机命令为psync，主机命令为bgsave）

步骤1：请求同步
步骤2：创建RDB同步数据
步骤3：恢复RDB同步数据
步骤4：请求部分同步数据
步骤5：恢复部分同步数据
至此，数据同步工作完成

命令传播阶段

通过ping命令，从机通知主机发送缓冲区内的命令

#### Sentinel模式（哨兵模式）

​	主从模式的弊端就是主数据库挂掉后，从数据库无法提供写的服务，所以产生了哨兵模式。

​	Sentinel是一个进程，用来监控redis进程的状态，Sentinel也可以启动多个形成一个集群。当Sentinel检测到主节点挂掉后，会将从节点升级为主节点，并修改其他所有节点的配置文件。当主节点再次启动后，会变为从节点。从节点故障后，哨兵不会进行故障转移。

​	机制：每个Sentinel会每秒钟一次的频率向所有的主从节点发送PING命令，如果实例的回复超过了指定的值（通过配置down-after-milliseconds,默认是30秒），则会被Sentinel标记为主观下线。如果主节点标记主观下线，其他Sentinel都要确认这个主节点下线，。当Sentinel的确认数量超过了配置值后，认为主节点客观下线。将每10一次发送的INFO命令变为1秒发送一次。

##### 具体的流程和细节

​	哨兵在进行主从切换过程中经历三个阶段

1.监控阶段

​	单个哨兵通过和主节点建立cmd链接，发送info命令，得到主节点的信息和各个从节点的信息，同时在主节点内存储哨兵实例的信息。主节点信息同步完毕后，向从节点建立链接，发送info命令，完善从节点的信息。

​	当其他哨兵加入进来时，链接到主节点后，发现主节点内有哨兵实例，通过发布订阅的形式，将两个哨兵实例的信息进行同步，后续的哨兵都是这样。

2.通知阶段

​	哨兵通过建立的cmd链接，发送相应的命令给节点，节点将状态信息返回，然后该哨兵通过发布订阅将信息同步给其他哨兵。

3.故障转移

​		一个哨兵发现主节点发送info命令没有回复，通知其他哨兵，并且将主节点状态修改为主观下线。其他哨兵也发送命令给主节点，如果确认的哨兵数超过了设定的值，就认为该主节点客观下线。然后哨兵之间需要选举出一个哨兵执行节点切换的任务。

​	每个哨兵都有一票，这票投给自己最先收到竞选通知的哨兵，直到某个哨兵票数超过一半以上，就认为该哨兵负责本次的切换。

​	哨兵从剩下的从节点中选出最优的主节点。先筛选出在线的，再筛选出响应快的，再筛选出和原先主节点同步时间最近的，最后还有多个的话，就按照优先原则，偏移量和uuid都会有影响。最后选出一个从节点，然后将这个从节点升级为主节点，将其他从节点的主节点的信息修改为新的主节点。后面如果掉线的主节点上线的话，也会修改为从节点。

#### Cluster模式（集群模式）

​	哨兵模式基本可以满足生产的需要，但是当数据量过大，导致一台机器无法满足时，这个时候就需要将数据进行分片存储，这就是集群模式。

​	Redis集群是一个由多个节点组成的分布式服务器群，它具有复制、高可用和分片特性；Redis集群没有中心节点，并且带有复制和故障转移特性，这可以避免单个节点成为性能瓶颈，或者因为某个节点下线而导致整个集群下线；

​	我们有3个主节点，3个从节点，每个主节点处理各自的数据，提供读写能力，从节点异步复制主节点的数据。一般读请求分配给从节点，写请求分配给主节点。

##### 数据分片

​	一个 Redis 集群包含 16384 个哈希槽（hash slot）， 它们的编号为0、1、2、3……16382、16383，这个槽是一个逻辑意义上的槽，实际上并不存在。redis中的每个key都属于这 16384 个哈希槽的其中一个，存取key时都要进行key->slot的映射计算。Redis Cluster中的每个Master节点都会负责一部分的槽，当有某个key被映射到某个Master负责的槽，那么这个Master负责为这个key提供服务。在Redis Cluster中，只有Master才拥有槽的所有权，如果是某个Master的slave，这个slave只负责槽的使用，但是没有所有权。

##### 故障转移

​	在cluster中，节点之间通过gossip协议进行通信。A节点会发送PING消息给B节点，若是在cluster_node_timeout时长内没有收到B节点的回复消息，则A节点会判定B节点已经下线了。这时候，A节点判定完后，会想集群广播B节点下线的消息。如果集群中的超过半数以上的节点都认为B节点下线后，B节点就会真正的下线。

​	当问题节点下线后，如果该下线节点是带有槽的主节点，则需要从它的从节点选出一个替换它，当问题节点的从节点发现其主节点下线时，将会触发故障恢复流程。但是并不是所有的从节点都能参与到故障恢复的流程中，若从节点与问题主节点的断线时间超过cluster_node_timeout * cluster-slave-validity-factor时，该从节点不能参与到后续恢复流程。

​	主要是通过对多个从节点使用不同的延迟选举时间来支持优先级问题。复制偏移量越大说明从节点延迟越低，那么它应该具有更高的优先级来替换故障主节点。

#### Redis中的脑裂现象

​	redis中的脑裂现象：哨兵将发现主节点下线后，将一个从节点升级为主节点，但是仍然有客户端连接旧的主节点，两个主节点造成数据没有同步，后续主节点恢复后，数据仍然丢失。可以通过设置第一个参数表示连接到master的最少slave数量，第二个参数表示slave连接到master的最大延迟时间这两个参数。如果两个条件都不满足，主节点就会拒绝同步数据。防止脑裂现象的产生。

### Redis中的发布订阅

​	Redis中的发布订阅可以使用匹配符，需要注意当没有消费者时，生产者发布的消息可能会丢失。

### Redis中的事务

​	Redis中的事务比较独特。事务开启后，会将命令都放入队列缓存中，其他客户端的命令不会放入。事务执行后，如果遇到命令格式错误，事务中所有的操作都不会被执行。但是如果命令格式正确，使用方式不对，例如对String执行hash方法，该命令不会被执行，其他正确命令仍然会被执行。

​	watch是为了完善redis事务的特点，在事务开始前监听某个key，如果事务中间key发生了变化，事务就会中断，不再执行。unwatch是为了取消监听，防止本次的监听对下次的事务产生影响。exec和discard也有同样的效果。

​	如果客户端发送的命令为 EXEC 、 DISCARD 、 WATCH 、 MULTI 四个命令的其中一个， 那么服务器立即执行这个命令。如果不是这四个命令，服务器并不立即执行这个命令， 而是将这个命令放入一个事务队列里面， 然后向客户端返回 QUEUED。某些命令执行出错也不会影响整个事务。

### Redis中的管道

​	Redis默认每次执行请求都会创建和断开一次连接池的操作，因此我们可以使用Redis的管道来一次性发送多条命令并返回多个结果，节约发送命令和创建连接的时间提升效率。

​	Redis中管道的实现是根据队列，可以保证数据的顺序性。

## Redis数据结构相关知识点

### String

* 一个键最大能存储 512MB，暂时没有找到原因

### List

* 列表最多可存储 232 - 1 元素 (4294967295, 每个列表可存储40多亿)。
* Redis list的实现为一个双向链表，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。

### Hash

* 列表最多可存储 232 - 1 元素 (4294967295, 每个列表可存储40多亿)。
* hash的原理也是数组加链表，扩容机制不太一样，是双table扩容，新的table要扩容时，是在执行完原油命令后，将就table上的元素慢慢复制到新table。这就是渐进式扩容。但是还是存在一些问题的，就是极端情况下，如果键一直在增加，新table也会很快触发扩容，这种情况下如何处理，这里其实估计只有后续看源码能够想清楚了。

### Set

* 列表最多可存储 232 - 1 元素 (4294967295, 每个列表可存储40多亿)。
* Redis 的 Set 是 String 类型的无序集合。集合成员是唯一的，这就意味着集合中不能出现重复的数据。
* set 的内部实现是一个 value永远为null的HashMap，实际就是通过计算hash的方式来快速排重的，这也是set能提供判断一个成员是否在集合内的原因。

### Zset

* 列表最多可存储 232 - 1 元素 (4294967295, 每个列表可存储40多亿)。
* Zset就是排序集合，在插入时需要制定元素的权，redis也是根据权来进行排序的。权相同时，则是根据字典排序。

### 跳跃表（skiplist）

​	跳跃表以有序的方式在层次化的链表中保存元素， 效率和平衡树媲美 —— 查找、删除、添加等操作都可以在对数期望时间下完成， 并且比起平衡树来说， 跳跃表的实现要简单直观得多。

​	跳表相当于是在链表的形式上添加层级来达到快速查询的目的。

## Redis相关命令

### Redis常用的基础命令

* 启动：`redis-server redis.conf`
* 连接：`redis-cli -h host -p port -a password`
* 获取配置：`CONFIG GET *`
* 设置配置：`ONFIG SET loglevel "notice"`
* 删除key：`del tset`
* 序列化给定 key ，并返回被序列化的值:`dump test`
* 检查给定 key 是否存在:`EXISTS test`
* 为给定 key 设置过期时间，以秒计:`EXPIRE test 120`
* 为给定 key 设置过期时间,接受的时间参数是 UNIX 时间戳: `EXPIREAT test 1623297047`
* 设置 key 的过期时间以毫秒计:`PEXPIRE test 120000`
* 设置 key 过期时间的时间戳(unix timestamp) 以毫秒计:`PEXPIREAT test 1623297047000`
* 查找所有符合给定模式( pattern)的 key :`keys tes*`
* 将当前数据库的 key 移动到给定的数据库 db 当中:`move test 1`
* 移除 key 的过期时间，key 将持久保持:`PERSIST test`
* 以毫秒为单位返回 key 的剩余的过期时间:`PTTL test`
* 以秒为单位，返回给定 key 的剩余生存时间(TTL, time to live):`TTL test`
* 从当前数据库中随机返回一个 key :`RANDOMKEY`
* 修改 key 的名称:`RENAME test test1`
* 仅当 newkey 不存在时，将 key 改名为 newkey:`RENAMENX test1 test`
* 迭代数据库中的数据库键:`SCAN cursor [MATCH pattern] [COUNT count]`
* 返回 key 所储存的值的类型:`type test`
* 验证密码是否正确：`AUTH qhlk@2017`
* 打印字符串：`ECHO "this is test"`(当你的字符串中间带特殊字符时，需要你带上双引号)
* 查看服务是否运行：`PING`
* 关闭当前连接：`QUIT`
* 切换到指定的数据库：`SELECT 0`(总共十六个库，0-15)
* 创建当前数据库的备份：`SAVE`
* 根据备份文件恢复redis数据库：`BGSAVE`

### 字符串相关命令

* 设置指定 key 的值：`set tset "hello"`也可以对存在的key执行就是修改
* 获取指定 key 的值：`GET test1`
* 返回 key 中字符串值的子字符：`GETRANGE test1 0 5`
* 将给定 key 的值设为 value ，并返回 key 的旧值(old value)：`GETSET test1 "this is test1."`
* 对 key 所储存的字符串值，获取指定偏移量上的位(bit)：`GETBIT test1 10`
* 获取所有(一个或多个)给定 key 的值：`MGET test test1`
* 对 key 所储存的字符串值，设置或清除指定偏移量上的位(bit)：`SETBIT test1 10 1`
* 将值 value 关联到 key ，并将 key 的过期时间设为 seconds (以秒为单位)：`SETEX test1 120 "this is test1"`
* 只有在 key 不存在时设置 key 的值：`SETNX test1 "hello"`
* 用 value 参数覆写给定 key 所储存的字符串值，从偏移量 offset 开始：`SETRANGE test2 1 "hahaha"`
* 返回 key 所储存的字符串值的长度：`STRLEN test2`
* 同时设置一个或多个 key-value 对：`mset key "2" key2 "this is "`
* 同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在：`MSETNX ke2 "test" key "haha"`
* 这个命令和 SETEX 命令相似，但它以毫秒为单位设置 key 的生存时间：`PSETEX key 120000 "this "`
* 将 key 中储存的数字值增一：`INCR key`
* 将 key 所储存的值加上给定的增量值（increment）：`INCRBY ke2 34`
* 将 key 中储存的数字值减一：`DECR ke2`
* key 所储存的值减去给定的减量值（decrement） ：`DECRBY ke2 3`
* 如果 key 已经存在并且是一个字符串， APPEND 命令将指定的 value 追加到该 key 原来值（value）的末尾：`APPEND key "end"`

### HASH相关命令

* 删除一个或多个哈希表字段：`HDEL testhash object`
* 查看哈希表 key 中，指定的字段是否存在：`HEXISTS testhash2 bug`
* 获取存储在哈希表中指定字段的值：`HGET testhash2 age`
* 获取在哈希表中指定 key 的所有字段和值：`HGETALL testhash2`
* 为哈希表 key 中的指定字段的整数值加上增量 increment ：`HINCRBY testhash2 age 1`
* 为哈希表 key 中的指定字段的浮点数值加上增量 increment ：`HINCRBYFLOAT testhash2 money 3.4`
* 获取所有哈希表中的字段：`HKEYS testhash2`
* 获取哈希表中字段的数量：`HLEN testhash2`
* 获取所有给定字段的值：`HMGET testhash2 redis mysql age`
* 同时将多个 field-value (域-值)对设置到哈希表 key 中：`HMSET testhash2 age 13 money 13.4 name lihua`
* 将哈希表 key 中的字段 field 的值设为 value ：`HSET testhash2 redis good mysql bad rabbitmq bad`(也可以设置多个字段)
* 只有在字段 field 不存在时，设置哈希表字段的值:`HSETNX testhash2 tag "null"`
* 获取哈希表中所有值:`HVALS testhash2`
* 迭代哈希表中的键值对:`HSCAN key cursor [MATCH pattern] [COUNT count]`

### LIST相关命令

* 移出并获取列表的第一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止：`BLPOP testlist2 10`
* 移出并获取列表的最后一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止：`BRPOP testlist2 10`
* 从列表中弹出一个值，将弹出的元素插入到另外一个列表中并返回它； 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止：`BRPOPLPUSH testlist testlist5 10`（从尾部取出，插入到另一个列表的头部）
* 通过索引获取列表中的元素：`LINDEX testlist 3`
* 在列表的元素前或者后插入元素：`LINSERT testlist AFTER test "after"`
* 获取列表长度：`LLEN testlist`
* 移出并获取列表的第一个元素：`LPOP testlist`
* 将一个或多个值插入到列表头部：`LPUSH testlist "hehe" "test222"`
* 将一个值插入到已存在的列表头部：`LPUSHX testlist1 "hehe" "test222"`
* 获取列表指定范围内的元素：`LRANGE testlist 0 2`
* 移除列表元素：`LREM testlist 0 "haha"`
* 通过索引设置列表元素的值：`LSET testlist 0 "this is test"`
* 对一个列表进行修剪(trim)，就是说，让列表只保留指定区间内的元素，不在指定区间之内的元素都将被删除：`LTRIM testlist 0 4`
* 移除列表的最后一个元素，返回值为移除的元素：`RPOP testlist`
* 移除列表的最后一个元素，并将该元素添加到另一个列表并返回：`RPOPLPUSH testlist testlist2`(头部插入)
* 在列表中添加一个或多个值：`RPUSH testlist "test" "test2"`(添加到尾部)
* 为已存在的列表添加值：`RPUSHX mylist "test"`

### SET相关命令

* 向集合添加一个或多个成员：`SADD myset "123" 3`（这里是多个成员，分别为字符串123和int 3）
* 获取集合的成员数：SCARD myset
* 返回第一个集合与其他集合之间的差异：`SDIFF myset myset1`(主要返回前面集合中的差异，后面集合元素不会返回)
* 返回给定所有集合的差集并存储在 destination 中：`SDIFFSTORE myset2 myset myset1`
* 返回给定所有集合的交集：`SINTER myset myset2`
* 返回给定所有集合的交集并存储在 destination 中：`SINTERSTORE myset3 myset myset2`
* 判断 member 元素是否是集合 key 的成员：`SISMEMBER myset "123"`
* 返回集合中的所有成员：`SMEMBERS myset1`
* 将 member 元素从 source 集合移动到 destination 集合：`SMOVE myset2 myset1 "3"`
* 移除并返回集合中的一个随机元素：`spop myset1`
* 返回集合中一个或多个随机数：`SRANDMEMBER myset1 2`
* 移除集合中一个或多个成员：`SREM myset1 "haha"`
* 返回所有给定集合的并集：`SUNION myset myset1`
* 所有给定集合的并集存储在 destination 集合中：`SUNIONSTORE myset4 myset myset1`
* 迭代集合中的元素：`SSCAN key cursor [MATCH pattern] [COUNT count]`

### 有序集合相关命令

* 向有序集合添加一个或多个成员，或者更新已存在成员的分数：`ZADD myzset 1 "test1" 2 "test2"`
* 获取有序集合的成员数：`ZCARD myzset`
* 计算在有序集合中指定区间分数的成员数：`ZCOUNT myzset 0 2`
* 有序集合中对指定成员的分数加上增量 increment：`ZINCRBY myzset 2 "test2"`
* 计算给定的一个或多个有序集的交集并将结果集存储在新的有序集合 destination 中：`ZINTERSTORE summyzset 2 myzset myzset2`(中间的数字2代表有两个set合并)
* 在有序集合中计算指定字典区间内成员数量：`ZLEXCOUNT myzset - +`(不清楚为啥)
* 通过索引区间返回有序集合指定区间内的成员：`ZRANGE myzset 0 -1 withscores`(withscores是表示将权一块显示出来，0代表排序的第一位，2代表排序集合的第三个元素)
* 通过字典区间返回有序集合的成员：`ZRANGEBYLEX myzset - +`(-号代表底，+号代表最高)
* 通过分数返回有序集合指定区间内的成员：`ZRANGEBYSCORE myzset (0 (2 withscores`(（代表不包含0，[代表包含,这里的分数就带代表权)
* 返回有序集合中指定成员的索引：`ZRANK myzset "test1"`(索引即时该元素在排序集合中的位置)
* 移除有序集合中的一个或多个成员：`ZREM myzset "test1"`
* 移除有序集合中给定的字典区间的所有成员：`ZREMRANGEBYLEX myzset2 - +`
* 移除有序集合中给定的排名区间的所有成员：`ZREMRANGEBYRANK myzset 0 0`
* 移除有序集合中给定的分数区间的所有成员：`ZREMRANGEBYSCORE myzset 0 5` 
* 返回有序集中指定区间内的成员，通过索引，分数从高到低：`ZREVRANGE myzset 0 -1 withscores`
* 返回有序集中指定分数区间内的成员，分数从高到低排序：`ZREVRANGEBYSCORE myzset 100 0`(也存在根据字典区间的命令)
* 返回有序集合中指定成员的排名，有序集成员按分数值递减(从大到小)排序：`ZRANK myzset lisi`(查询lisi在有序集合中的排名)
* 返回有序集中，成员的分数值：`ZSCORE myzset lisi`
* 计算给定的一个或多个有序集的并集，并存储在新的 key 中：`ZUNIONSTORE out 2 zset1 zset2 WEIGHTS 2 3`(看不懂)
* 迭代有序集合中的元素（包括元素成员和元素分值）：`ZSCAN site 0 match "R*"`

### HyperLogLog相关命令

​	redis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的、并且是很小的。在Redis里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基 数。比如数据集 {1, 3, 5, 7, 5, 7, 8}， 那么这个数据集的基数集为 {1, 3, 5 ,7, 8}, 基数(不重复元素)为5。 基数估计就是在误差可接受的范围内，快速计算基数。但是HyperLogLog 只会计算基数，不会存储元素本身。

* 添加指定元素到 HyperLogLog 中：`PFADD mypf "redis"`(后面可以跟多个元素，元素可以不带引号，存储的都是字符串类型)
* 返回给定 HyperLogLog 的基数估算值：`PFCOUNT mypf`
* 将多个 HyperLogLog 合并为一个 HyperLogLog：`PFMERGE mypf3 mypf mypf2`

### 发布订阅相关命令

Redis 发布订阅 (pub/sub) 是一种消息通信模式：发送者 (pub) 发送消息，订阅者 (sub) 接收消息。Redis 客户端可以订阅任意数量的频道。

* 订阅一个或多个符合给定模式的频道：`PSUBSCRIBE testchannel`(后面参数类似于正则表达式)
* 查看订阅与发布系统状态：`PUBSUB channels`(目前不清楚用法，现在参数固定)
* 将信息发送到指定的频道：PUBLISH testchannel "this is test"
* 退订所有给定模式的频道：PUNSUBSCRIBE mychannel 
* 订阅给定的一个或多个频道的信息：SUBSCRIBE testchannel
* 指退订给定的频道：UNSUBSCRIBE mychannel

### Redis中的事务

* 取消事务，放弃执行事务块内的所有命令:`DISCARD`
* 执行所有事务块内的命令:`EXEC`
* 标记一个事务块的开始:`MULTI`（连续执行两次multi不会导致事务回滚）
* 取消 WATCH 命令对所有 key 的监视:UNWATCH（使用方法是在watch前面，并不是在事务中取消监视，而是在监视前取消所有的其他监视，所以只要调用了watch，key被修改，就会出错。只是为了完善redis事务的一个点）
* 监视一个(或多个) key ，如果在事务执行之前这个(或这些) key 被其他命令所改动，那么事务将被打断:`WATCH lock`（在multi里面执行watch不会导致事务回滚。）

## Redis在SpringBoot中的应用



## Redis实际中的应用和解决方案

### 缓存击穿

​	对于一些设置了过期时间的key，如果这个key可能会在某些时间点被超高并发地访问，是一个热点数据，当这个key过期后，这个时间点有大量并发去请求这个key，该key没有命中，大量的请求穿透到数据库服务器。

​	解决方案：有两种方案，1）将热点数据设置永不过期。2）使用互斥锁：先从redis获取数据，如果redis中数据没有，去争夺锁，拿到锁的线程去查询数据库，然后见过结果放入redis中。其他没抢到的，等一段时间，再执行查询等方法，重新从redis中获取数据。锁是需要按照key 维度去加锁。例如akey的锁不能影响其他key的查询。

### 缓存雪崩

​	大量的key设置了相同的过期时间，导致在缓存在同一时刻全部失效，造成瞬时DB请求量大、压力骤增，引起雪崩。

​	解决方案：1）可以给缓存时间加上一个随机偏移量，例如一个小时的缓存时间，可以将这个时间再10分钟内随机，将失效时间平均到10分钟内。2）和上面的缓存击穿一样，加一个互斥锁，减少数据库的访问次数。3）设置热点数据永不过期，需要考虑数据的同步时间间隔和数据异常的处理情况。

### 缓存穿透

​	访问一个一定不存在的key，缓存不起作用，请求会穿透到DB，流量大时DB会挂掉。因为查不到数据，所以后续的查询仍然会请求数据库。

​	解决方案有以下：1）如果是大量的不存在的key，可以认为是受到的攻击，可以在最外层做一层过滤。2）当数据库查询的结果为空时，可以将这个null结果做个缓存，设置一个较短的过期时间。当查询的key都是不存在的时候且不重复，这个作用也是比较小的。3）布隆过滤器。

##### 布隆过滤器

​	有一个bitset集合，还有一组hash算法，将一个key通过这组hash算法计算得到一组下标。将bitset中这组下标的位置设置为true，如果一个key通过这样的计算，得到的一组下标的位置不全为true，则这个key一定不存在，当都是true时，这个key可能存在。降低误判率也有方法：增大bitset集合的长度，增多hash算法，得到更多的下标。一般是增加长度，因为长度如果过短的话，增加hash算法其实意义不大。

### 缓存一致性

​	当数据时效性要求很高时，需要保证缓存中的数据与数据库中的保持一致，需要保证缓存节点和副本中的数据也保持一致，不能出现差异现象。

​	解决方法：更新数据库后，直接让缓存失效。

### 面试中遇到的问题

* 项目中什么地方用到redis，为什么使用redis？

我们项目中redis的主要作用就是存储设备点位的信息，主要是存储设备当前状态的值，还有就是用户的token信息也是存储在redis中。当然，项目中还有一些其他的地方我没有涉及，可能这部分的信息也有存储在redis中的需求。因为项目是在我来公司之前成立的，所以技术的选型我并没有参与，对于选用redis并不知道当时出于什么考虑。我们redis使用的是单机服务，对于我们的项目来说可能够用了，但是并没有考虑到高可用，小公司对于技术的优化可能没有强烈的需求，我也是在私下会对这部分有个了解。我对于公司的redis优化的思路是采用哨兵模式进行高可用的优化。因为单机模式会存在宕机的可能，集群模式主要是为了应对单个服务器无法存储全部的数据的情况，所以我认为哨兵模式对于我们的项目来说比较适合。后面就介绍一下哨兵模式的一些特点和搭建中遇到的问题。